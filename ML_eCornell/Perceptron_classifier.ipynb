{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDsdK0Mtlm-a",
        "outputId": "f76bee6f-c218-4325-8b3f-1c7e661d050c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You're running python 3.9.16\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "sys.path.append('/home/codio/workspace/.guides/hf')\n",
        "from helper import *\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "print('You\\'re running python %s' % sys.version.split(' ')[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Perceptron**\n",
        "The perceptron is a basic linear classifier. The following cells will walk you through steps and ask you to finish the necessary functions in a pre-defined order. Code cells requiring your input will display # YOUR CODE HERE and graded portions will be adequately labeled. Unless specified otherwise, do not use loops.\n",
        "\n",
        "# **Part One: Perceptron Update **[Graded]\n",
        "Implement the function below to update the perceptron given an input vector, label, and weight vector. Do not check if an update is necessary. This function can assume that it is only called when an update should be performed. Hint: You simply need to implement ùê∞‚Üêùê∞+ùë¶ùê±\n",
        "."
      ],
      "metadata": {
        "id": "QgGyWB2Kl2Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_update(x,y,w):\n",
        "    \"\"\"\n",
        "    function w=perceptron_update(x,y,w);\n",
        "\n",
        "    Updates the perceptron weight vector w using x and y\n",
        "    Input:\n",
        "    x : input vector of d dimensions (d)\n",
        "    y : corresponding label (-1 or +1)\n",
        "    w : weight vector of d dimensions\n",
        "\n",
        "    Output:\n",
        "    w : weight vector after updating (d)\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    update = np.multiply(y,x)\n",
        "    w_new = w+update\n",
        "    return w_new\n",
        "\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "Zas4iK-WmJ8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# little test\n",
        "y = -1\n",
        "x = np.random.randint(low=-2, high=2, size=10)\n",
        "w = np.random.randint(low=0, high=2, size=10)*2 - 1\n",
        "print(f'y\\t= {y}')\n",
        "print(f'x\\t= {x}')\n",
        "print(f'w_old\\t= {w}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wERb-W5noBjF",
        "outputId": "8e3c6fd1-5674-4c02-c801-9c538966620e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y\t= -1\n",
            "x\t= [ 1  0  0  0 -1 -2 -2  0  0  1]\n",
            "w_old\t= [ 1  1  1  1  1  1  1  1  1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update = np.dot(y,x)\n",
        "print(update)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7kw706nsZpE",
        "outputId": "fd23f620-541d-4386-a3e7-0e85b69d78dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1  0  0  0  1  2  2  0  0 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update = y*x\n",
        "print(update)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtRA4FrbvHaN",
        "outputId": "f8afd14e-8c03-4419-d815-5a39b3f1e043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1  0  0  0  1  2  2  0  0 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update = np.multiply(y,x)\n",
        "print(update)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZHjWWN7ve1B",
        "outputId": "b138b2e1-3939-4868-fcbf-a29c20002293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1  0  0  0  1  2  2  0  0 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_new = w+update\n",
        "print(w_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IteJmzlsf2O",
        "outputId": "44c9a370-f72e-4a88-ad84-2c0fcdbdcb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  2  3  3  1  1 -2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_new.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBZznhAsD88C",
        "outputId": "2fb47579-8633-4319-8e7f-45cdc03c79a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  2,  3,  3,  1,  1, -2])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_new.T*x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JpuSGRLEF1O",
        "outputId": "2a980208-68af-4429-bdcc-0183205edab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0, -2, -6, -6,  0,  0, -2])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_new @ x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUxLVtvbEkk_",
        "outputId": "a0442099-0897-43be-b919-f404123e2027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-16"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_new.dot(x.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL98wq3_Eu5b",
        "outputId": "dbad73c7-4d44-42b0-fb07-207d88499303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-16"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_new = perceptron_update(x, y, w)\n",
        "print(f'w_new\\t= {w_new}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "O2XTZ6byqyRf",
        "outputId": "2b3d9cc7-5416-44d2-8dce-7abd8c802992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-7f609ef9b2eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptron_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'w_new\\t= {w_new}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-02c70dc36c6d>\u001b[0m in \u001b[0;36mperceptron_update\u001b[0;34m(x, y, w)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mw_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'type' and 'type'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part Two: Implement Perceptron** [Graded]\n",
        "Implement function perceptron. This should contain a loop that calls perceptron_update until it converges or the maximum iteration count, 100, has been reached. Make sure you randomize the order of the training data on each iteration (you can use np.random.permutation() to do this.)\n",
        "\n",
        "We assume that the  ùëëùë°‚Ñé\n",
        "  dimension of  ùê±ùëñ\n",
        "  is 1, and so the last dimension of  ùê∞\n",
        "  represents the bias term, which we implicitly absorbed into the weight vector. So you can implement the pseudocode directly."
      ],
      "metadata": {
        "id": "HhI6T0vhw_Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron(xs, ys):\n",
        "    \"\"\"\n",
        "    function w=perceptron(xs,ys);\n",
        "\n",
        "    Returns the weight vector learned by the Perceptron classifier.\n",
        "    We assume that the last dimension of each xs is 1.\n",
        "\n",
        "    Input:\n",
        "    xs : n input vectors of d dimensions (nxd matrix)\n",
        "    ys : n labels (-1 or +1)\n",
        "\n",
        "    Output:\n",
        "    w : weight vector (d)\n",
        "    b : bias term\n",
        "    \"\"\"\n",
        "\n",
        "    n, d = xs.shape     # so we have n input vectors, of d dimensions each\n",
        "    w = np.zeros(d)\n",
        "    b = 0.0\n",
        "    iter = 0\n",
        "    m = 0\n",
        "\n",
        "    for i in np.random.permutation(n): #to randomise the order of the training data on each iteration\n",
        "        classified = y[i]*(w.T*x[i]+ b) #\n",
        "        while classified <= 0:\n",
        "            iter +=1\n",
        "            w += perceptron_update\n",
        "            b +=y\n",
        "        if classified >0:\n",
        "            break\n",
        "        elif iter == n:\n",
        "            break\n",
        "    return w, b\n",
        "\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "V_KU2sJ4xOAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several issues with this code:\n",
        "\n",
        "The function perceptron_update is not defined, so it will raise a NameError when the function is called.\n",
        "The variable y is not defined. It is likely that ys is supposed to be used instead.\n",
        "The line b += y should be b += ys[i], as ys is the array containing the labels, and we need to use the label corresponding to the current input vector.\n",
        "The line classified = y[i]*(w.T*x[i]+ b) should be classified = ys[i]*(np.dot(w, xs[i]) + b), as ys is the array containing the labels, and we should use np.dot to compute the dot product of the weight vector and the input vector.\n",
        "The break statement inside the loop will terminate the loop prematurely, so the function may not converge to a solution."
      ],
      "metadata": {
        "id": "aMl_TiwKUIXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def perceptron(xs, ys):\n",
        "    \"\"\"\n",
        "    function w=perceptron(xs,ys);\n",
        "\n",
        "    Returns the weight vector learned by the Perceptron classifier.\n",
        "    We assume that the last dimension of each xs is 1.\n",
        "\n",
        "    Input:\n",
        "    xs : n input vectors of d dimensions (nxd matrix)\n",
        "    ys : n labels (-1 or +1)\n",
        "\n",
        "    Output:\n",
        "    w : weight vector (d)\n",
        "    b : bias term\n",
        "    \"\"\"\n",
        "\n",
        "    n, d = xs.shape     # so we have n input vectors, of d dimensions each\n",
        "    w = np.zeros(d)\n",
        "    b = 0.0\n",
        "    iter = 0\n",
        "\n",
        "    while True: #while loop continues until a condition is met\n",
        "        for i in np.random.permutation(n):\n",
        "            if ys[i]*(np.dot(w, xs[i]) + b) <= 0: #if misclassified\n",
        "                w += np.multiply(ys[i],xs[i]) #update corresponding weight with yx for that input vector\n",
        "                b += ys[i] #update corresponding bias with y for that input vector\n",
        "        iter += 1 #update iteration number\n",
        "        if ys[i]*(np.dot(w, xs[i]) + b) > 0 or iter == n: #if classified correctly, or maximum iterations\n",
        "            break #end the loop\n",
        "\n",
        "    return w, b #and return the latest updated w and b\n"
      ],
      "metadata": {
        "id": "I1zNkz6YYIML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 100\n",
        "d = 10"
      ],
      "metadata": {
        "id": "79Rp4wJq9V9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(N,d)\n",
        "w = np.random.rand(1,d)"
      ],
      "metadata": {
        "id": "4RNzZcz79Wy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_Perceptron1():\n",
        "    N = 100;\n",
        "    d = 10;\n",
        "    x = np.random.rand(N,d)\n",
        "    w = np.random.rand(1,d)\n",
        "    y = np.sign(w.dot(x.T))[0]\n",
        "    w, b = perceptron(x,y)\n",
        "    preds = classify_linear_grader(x,w,b)\n",
        "    return np.array_equal(preds.reshape(-1,),y.reshape(-1,))"
      ],
      "metadata": {
        "id": "UE9bRrml_r94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_Perceptron2():\n",
        "    x = np.array([ [-0.70072, -1.15826],  [-2.23769, -1.42917],  [-1.28357, -3.52909],  [-3.27927, -1.47949],  [-1.98508, -0.65195],  [-1.40251, -1.27096],  [-3.35145,-0.50274],  [-1.37491,-3.74950],  [-3.44509,-2.82399],  [-0.99489,-1.90591],   [0.63155,1.83584],   [2.41051,1.13768],  [-0.19401,0.62158],   [2.08617,4.41117],   [2.20720,1.24066],   [0.32384,3.39487],   [1.44111,1.48273],   [0.59591,0.87830],   [2.96363,3.00412],   [1.70080,1.80916]])\n",
        "    y = np.array([1]*10 + [-1]*10)\n",
        "    w, b =perceptron(x,y)\n",
        "    preds = classify_linear_grader(x,w,b)\n",
        "    return np.array_equal(preds.reshape(-1,),y.reshape(-1,))"
      ],
      "metadata": {
        "id": "27StxAwT_2i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GG31VgXwACHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have perceptron implemented, we can visualize how it finds w that classify points in a 2-dimensional plane. In this example, we center the data by subtracting the common mean vector of  ùê±ùëñ\n",
        "  from each of  ùê±ùëñ\n",
        " . Consequently, the perceptron algorithm will learn the bias term (the last dimension of  ùê∞\n",
        "  as 0)."
      ],
      "metadata": {
        "id": "x_bGy0xyhGQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_perceptron_2D(x, y_true, w_true, y_pred, w_pred, b):\n",
        "    w_pred = w_pred.flatten()\n",
        "    w_true = w_true.flatten()\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    # Plot points\n",
        "    plt.scatter(x[:, 0], x[:, 1], c=y_true, cmap='viridis')\n",
        "\n",
        "    grid_lim = np.max(abs(x[:, :-1]))\n",
        "\n",
        "    def calc_x2(b, x1, w):\n",
        "        return -(b+w[0] * x1) / w[1]\n",
        "\n",
        "    # Make arrow for w_true: normalize by magnitude, then stretch to grid lim\n",
        "    w_true_mag = np.sqrt(np.sum(w_true[:-1] ** 2))\n",
        "    plt.quiver([0], [0], [(w_true[0] / w_true_mag) * grid_lim], [(w_true[1] / w_true_mag) * grid_lim],\n",
        "               scale=1, units='xy', color='k')\n",
        "    plt.annotate('w_true', xy=w_true[:-1] / w_true_mag * grid_lim + [.05, 0.], fontsize=12, color='k')\n",
        "\n",
        "    # Make decision line perpendicular to arrow\n",
        "    plt.plot([grid_lim, -grid_lim], [calc_x2(b, grid_lim, w_true), calc_x2(b, -grid_lim, w_true)],\n",
        "             color='k', label='true decision line')\n",
        "\n",
        "    # Repeat for w_pred\n",
        "    w_pred_mag = np.sqrt(np.sum(w_pred[:-1] ** 2))\n",
        "    plt.quiver([0], [0], [(w_pred[0] / w_pred_mag) * grid_lim], [(w_pred[1] / w_pred_mag) * grid_lim],\n",
        "               scale=1, units='xy', color='r')\n",
        "    plt.annotate('w_pred', xy=w_pred[0] / w_pred_mag * grid_lim + [0., 0.1], fontsize=12, color='r')\n",
        "    plt.plot([grid_lim, -grid_lim], [calc_x2(b, grid_lim, w_pred), calc_x2(b, -grid_lim, w_pred)],\n",
        "             color='r', label='pred decision line')\n",
        "\n",
        "    plt.title(f'True and predicted decision line')\n",
        "    plt.xlim(-grid_lim, grid_lim)\n",
        "    plt.ylim(-grid_lim, grid_lim)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PYakkzfrhsJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N, d = 500, 2 # count of observations and features\n",
        "np.random.seed(1)\n",
        "x = np.random.rand(N, d)\n",
        "x -= np.mean(x) # by subtracting mean, we move the features to range [-0.5, 0.5]\n",
        "#x = np.hstack([ x, np.ones((N, 1)) ]) # Add constant dimension -- a column of 1s at the end\n",
        "\n",
        "w_true = np.random.rand(1,d) # generate w from which we compute labels\n",
        "w_true -= np.mean(w_true) # Only rotates the weight vector in 2d space\n",
        "\n",
        "y_true = np.sign(w_true.dot(x.T))[0]\n",
        "y_true[0] = -1 * y_true[0] # this makes a separation line impossible to compute and we can plot both w_true and w_pred distinctly\n",
        "\n",
        "w_pred, b = perceptron(x, y_true)\n",
        "y_pred = classify_linear_grader(x, w_pred, b).astype(int)\n",
        "\n",
        "plot_perceptron_2D(x, y_true, w_true, y_pred, w_pred, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "pzWq5n7Jhs49",
        "outputId": "3ff1bc38-8b7d-416f-b326-3ff6804a9f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f2d73e0e9c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mw_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_linear_grader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplot_perceptron_2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'classify_linear_grader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of input vectors\n",
        "N = 100\n",
        "\n",
        "# generate random (linarly separable) data\n",
        "xs = np.random.rand(N, 2)*10-5\n",
        "\n",
        "# defining random hyperplane\n",
        "w0 = np.random.rand(2)\n",
        "b0 = np.random.rand()*2-1;\n",
        "\n",
        "# assigning labels +1, -1 labels depending on what side of the plane they lie on\n",
        "ys = np.sign(xs.dot(w0)+b0)\n",
        "\n",
        "# call perceptron to find w from data\n",
        "w,b = perceptron(xs.copy(),ys.copy())\n",
        "\n",
        "# test if all points are classified correctly\n",
        "assert (all(np.sign(ys*(xs.dot(w)+b))==1.0))  # yw'x should be +1.0 for every input\n",
        "print(\"Looks like you passed the Perceptron test!\")\n",
        "\n",
        "# we can make a pretty visualization\n",
        "visboundary(w,b,xs,ys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "PJ1VUSquh3zm",
        "outputId": "0de63025-ee14-420d-8909-4980cba62c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks like you passed the Perceptron test!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c6e69c8bff14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# we can make a pretty visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mvisboundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'visboundary' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part Three: Make Predictions** [Graded]\n",
        "Implement classify_linear that applies the weight vector (with implicit bias term) to the input vector. Make sure that the predictions returned are either 1 or -1."
      ],
      "metadata": {
        "id": "KE5Nj_yHkC8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_linear(xs,w,b=None):\n",
        "    \"\"\"\n",
        "    function preds=classify_linear(xs,w,b)\n",
        "\n",
        "    Make predictions with a linear classifier\n",
        "    Input:\n",
        "    xs : n input vectors of d dimensions (nxd) [could also be a single vector of d dimensions]\n",
        "    w : weight vector of dimensionality d\n",
        "    b : bias (scalar)\n",
        "\n",
        "    Output:\n",
        "    preds: predictions (1xn)\n",
        "    \"\"\"\n",
        "    w = w.flatten()\n",
        "    predictions=np.zeros(xs.shape[0])\n",
        "\n",
        "    predictions = np.sign(np.dot(w, xs)+b)\n",
        "\n",
        "    raise NotImplementedError()\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "2rJJLvfQkIqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_linear(xs,w,b=None):\n",
        "    \"\"\"\n",
        "    function preds=classify_linear(xs,w,b)\n",
        "\n",
        "    Make predictions with a linear classifier\n",
        "    Input:\n",
        "    xs : n input vectors of d dimensions (nxd) [could also be a single vector of d dimensions]\n",
        "    w : weight vector of dimensionality d\n",
        "    b : bias (scalar)\n",
        "\n",
        "    Output:\n",
        "    preds: predictions (1xn)\n",
        "    \"\"\"\n",
        "    w = w.flatten()\n",
        "    predictions=np.zeros(xs.shape[0])\n",
        "\n",
        "    if b is None:\n",
        "      predictions = np.sign(w@xs.T)\n",
        "    if b is not None:\n",
        "      predictions = np.sign((w@xs.T)+b)\n",
        "\n",
        "    raise NotImplementedError()\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "exLnZyK3yw4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_linear(xs,w,b=None):\n",
        "    \"\"\"\n",
        "    function preds=classify_linear(xs,w,b)\n",
        "\n",
        "    Make predictions with a linear classifier\n",
        "    Input:\n",
        "    xs : n input vectors of d dimensions (nxd) [could also be a single vector of d dimensions]\n",
        "    w : weight vector of dimensionality d\n",
        "    b : bias (scalar)\n",
        "\n",
        "    Output:\n",
        "    preds: predictions (1xn)\n",
        "    \"\"\"\n",
        "    w = w.flatten()\n",
        "    predictions=np.zeros(xs.shape[0])\n",
        "\n",
        "    for i in range(xs.shape[0]):\n",
        "      if np.dot(w,xs[i]) + b >=0:\n",
        "        predictions[i] = 1\n",
        "      if np.dot(w,xs[i]) + b <0:\n",
        "        predictions[i] = -1\n",
        "\n",
        "    raise NotImplementedError()\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "u50WoG97ouGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In version above, we get the error \"Your code raises the following exception:\n",
        " TypeError: unsupported operand type(s) for +: 'float' and 'NoneType'\". This error message indicates that the b argument is None and you are trying to add it to a float value. To fix the error, you can add a check to see if b is not None before using it in your code. Here's a modified version of your function:\n",
        "\n",
        "\n",
        "In this version below, we first check if b is not None, and if it is not, we add it to the dot product of w and xs[i] to get the value of y. If b is None, we skip adding it to the dot product."
      ],
      "metadata": {
        "id": "hqrswXJZvzNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_linear(xs,w,b=None):\n",
        "    \"\"\"\n",
        "    function preds=classify_linear(xs,w,b)\n",
        "\n",
        "    Make predictions with a linear classifier\n",
        "    Input:\n",
        "    xs : n input vectors of d dimensions (nxd) [could also be a single vector of d dimensions]\n",
        "    w : weight vector of dimensionality d\n",
        "    b : bias (scalar)\n",
        "\n",
        "    Output:\n",
        "    preds: predictions (1xn)\n",
        "    \"\"\"\n",
        "    w = w.flatten()\n",
        "    predictions=np.zeros(xs.shape[0])\n",
        "\n",
        "    for i in range(xs.shape[0]):\n",
        "        if b is not None:\n",
        "            y = np.dot(w,xs[i]) + b\n",
        "        else:\n",
        "            y = np.dot(w,xs[i])\n",
        "        if y >=0:\n",
        "            predictions[i] = 1\n",
        "        if y < 0:\n",
        "            predictions[i] = -1\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "GLYi1rTjughN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_linear(xs,w,b=None):\n",
        "    \"\"\"\n",
        "    function preds=classify_linear(xs,w,b)\n",
        "\n",
        "    Make predictions with a linear classifier\n",
        "    Input:\n",
        "    xs : n input vectors of d dimensions (nxd) [could also be a single vector of d dimensions]\n",
        "    w : weight vector of dimensionality d\n",
        "    b : bias (scalar)\n",
        "\n",
        "    Output:\n",
        "    preds: predictions (1xn)\n",
        "    \"\"\"\n",
        "    w = w.flatten()\n",
        "    predictions=np.zeros(xs.shape[0])\n",
        "\n",
        "    for i in range(xs.shape[0]):\n",
        "        if b is None:\n",
        "            predictions[i] += np.sign(np.dot(w,xs[i]))\n",
        "        else:\n",
        "            predictions[i] += np.sign(np.dot(w,xs[i])+b)\n",
        "    return predictions\n",
        "\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "0RxL3IYKwH_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scikit-learn approach\n",
        "\n",
        "[Scikit-learn](https://scikit-learn.org/stable/index.html) (or `sklearn`) is a Python library with implementations for numerous machine learning and data science models. Scikit-learn provides a standard step-by-step training procedure across different machine learning models, simplifying model training and prediction. The typical process for selecting, training, and predicting with a model of your choice is as follows:\n",
        "\n",
        "\n",
        "1. Define the classifier `clf` using a call to the model class.\n",
        "2. Train `clf` using `clf.fit` on training data.\n",
        "3. Predict on test data using `clf.predict`, getting predictions as output.\n",
        "\n",
        "Scikit-learn provides a [perceptron model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html). We provide a brief demonstration of its usage below."
      ],
      "metadata": {
        "id": "PnErPnpKxiZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSK1DLfTxkVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}